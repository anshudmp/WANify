# WANify
"WANify" is a tool based on top of iPerf 3.0, which measures accurate runtime bandwidths (BWs) for a cluster. It supports a decision tree-based Random Forest (RF) model for low-cost and precise prediction of runtime BWs by utilizing short-duration (1s) snapshot BWs. The choice of features in RF, such as the physical distance between datacenters (DCs) and the number of DCs, help adapt to various cluster sizes and multiple cloud providers. Moreover, the tool supports periodic monitoring, that is, it can be configured to collect additional static/dynamic/snapshot datasets at fixed intervals. The goal of this tool is to help Geo-distributed Data Analytics (GDA) applications in determining actual runtime BWs for network-aware policies.

# Configurations
All configurations related to the tool can be found inside config.cfg. One of the important configurations is the image ID for respective regions, i.e., AWS us-east-1: <image_id>, etc. Such information is essential to launch instances from scratch that will be used during monitoring. An easy way to accomplish this for the entire cluster is by copying the image from one region to all other required regions. Each image must contain Python 3.0 and iPerf 3.0. Additional steps can be found in <provider>/setup/README.txt.

Files, such as 'src/predict/livePredictor.py', 'src/predict/rfTrain.py', 'src/predict/genRefactoringVector.py' and 'src/optimization/greedyOptimization.py' contain path information, which might need to be updated after cloning this project. This is only required once when setting up the project.

# BW Monitoring and Model Generation
Additional datasets can be generated by running the following command from the project's home directory.

```python3 src/main.py```

# Generating Refactoring-vector
A "refactoring-vector" is required when the type of DCs to be used in model prediction have proportionally different BWs than the DCs that were originally used for model training. E.g., AWS DCs that have 200-400 Mbps BW were used initially for model training, but the model is now used for predicting runtime BWs in a multi-cloud cluster (consisting of both AWS and Google Cloud). If in this case, Google Cloud DCs typically have 400-600 Mbps BW, then refactoring is necessary. By default, the dependent codes and the model implicitly support a refactoring-vector of all 1s.

```python3 src/predict/genRefactoringVector```

# Predicting Runtime BW
Note that re-generation of the prediction model might be required when scikit-learn libraries are different between the generated model and the user's workspace. If that is the case, set both 'buildModel' and 'trainModeOnly' keys to 'True' (in config.cfg) and run the following command.

```python3 src/main.py```

To predict the runtime BW for a cluster, run the following command. Here <mode> can take one value from the set {1, 2, 3}. 1 removes the monitoring files after prediction, 2 persists the monitoring files after prediction and 3 predicts the runtime BWs based on the persisted monitoring files. This is done to ensure light-weight monitoring support for continuous periodic monitoring (in the interval of minutes, hours, etc.).

```python3 src/predict/livePredictor.py <mode>```
